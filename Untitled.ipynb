{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from glob import glob\n",
    "from cv2 import imwrite\n",
    "import cv2\n",
    "from packnet_sfm.models.model_wrapper import ModelWrapper\n",
    "from packnet_sfm.datasets.augmentations import resize_image, to_tensor\n",
    "from packnet_sfm.utils.horovod import hvd_init, rank, world_size, print0\n",
    "from packnet_sfm.utils.image import load_image\n",
    "from packnet_sfm.utils.config import parse_test_file\n",
    "from packnet_sfm.utils.load import set_debug\n",
    "from packnet_sfm.utils.depth import write_depth, inv2depth, viz_inv_depth\n",
    "from packnet_sfm.utils.logging import pcolor\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def infer_and_save_depth(\n",
    "    input_file, output_file, model_wrapper, image_shape, half, save\n",
    "):\n",
    "    \"\"\"\n",
    "    Process a single input file to produce and save visualization\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_file : str\n",
    "        Image file\n",
    "    output_file : str\n",
    "        Output file, or folder where the output will be saved\n",
    "    model_wrapper : nn.Module\n",
    "        Model wrapper used for inference\n",
    "    image_shape : Image shape\n",
    "        Input image shape\n",
    "    half: bool\n",
    "        use half precision (fp16)\n",
    "    save: str\n",
    "        Save format (npz or png)\n",
    "    \"\"\"\n",
    "    if not is_image(output_file):\n",
    "        # If not an image, assume it's a folder and append the input name\n",
    "        os.makedirs(output_file, exist_ok=True)\n",
    "        output_file = os.path.join(output_file, os.path.basename(input_file))\n",
    "\n",
    "    # change to half precision for evaluation if requested\n",
    "    dtype = torch.float16 if half else None\n",
    "\n",
    "    # Load image\n",
    "    image = load_image(input_file)\n",
    "    # Resize and to tensor\n",
    "    image = resize_image(image, image_shape)\n",
    "    image = to_tensor(image).unsqueeze(0)\n",
    "\n",
    "    # Send image to GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        image = image.to(\"cuda:{}\".format(rank()), dtype=dtype)\n",
    "\n",
    "    # Depth inference (returns predicted inverse depth)\n",
    "    pred_inv_depth = model_wrapper.depth(image)[\"inv_depths\"][0]\n",
    "\n",
    "    if save == \"npz\" or save == \"png\":\n",
    "        # Get depth from predicted depth map and save to different formats\n",
    "        filename = \"{}.{}\".format(os.path.splitext(output_file)[0], save)\n",
    "        print(\n",
    "            \"Saving {} to {}\".format(\n",
    "                pcolor(input_file, \"cyan\", attrs=[\"bold\"]),\n",
    "                pcolor(filename, \"magenta\", attrs=[\"bold\"]),\n",
    "            )\n",
    "        )\n",
    "        # write_depth(filename, depth=inv2depth(pred_inv_depth))\n",
    "    else:\n",
    "        # Prepare RGB image\n",
    "        rgb = image[0].permute(1, 2, 0).detach().cpu().numpy() * 255\n",
    "        # Prepare inverse depth\n",
    "        viz_pred_inv_depth = viz_inv_depth(pred_inv_depth[0]) * 255\n",
    "        # Concatenate both vertically\n",
    "        image = np.concatenate([rgb, viz_pred_inv_depth], 0)\n",
    "        # Save visualization\n",
    "        print(\n",
    "            \"Saving {} to {}\".format(\n",
    "                pcolor(input_file, \"cyan\", attrs=[\"bold\"]),\n",
    "                pcolor(output_file, \"magenta\", attrs=[\"bold\"]),\n",
    "            )\n",
    "        )\n",
    "        imwrite(output_file, image[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
